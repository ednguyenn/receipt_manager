# backend/lambda_functions/search_receipts_llm/handler_search_llm.py

import boto3
import json
import os
import openai  # For OpenAI GPT or AWS Bedrock integration
from boto3.dynamodb.conditions import Attr

# Initialize DynamoDB
dynamodb = boto3.resource('dynamodb')
table_name = os.environ.get('DYNAMODB_TABLE', 'ReceiptsTable')
receipts_table = dynamodb.Table(table_name)

# OpenAI API key from environment variables (replace with AWS Bedrock if needed)
openai.api_key = os.environ.get('OPENAI_API_KEY')

def lambda_handler(event, context):
    body = json.loads(event['body'])
    query = body.get('query', '').strip()

    if not query:
        return {
            'statusCode': 400,
            'body': json.dumps({'error': 'Query parameter is required.'})
        }

    # Use LLM (e.g., OpenAI GPT) to interpret the natural language query
    filters = generate_filters(query)

    # Query DynamoDB using filters generated by the LLM
    filter_expression = Attr('vendor_name').contains(filters['vendor_name']) & \
                        Attr('transaction_date').between(filters['transaction_date']['start'], filters['transaction_date']['end'])

    response = receipts_table.scan(
        FilterExpression=filter_expression
    )

    return {
        'statusCode': 200,
        'body': json.dumps(response['Items'])
    }

def generate_filters(search_query):
    """
    Uses an LLM (e.g., OpenAI or AWS Bedrock) to generate DynamoDB filters based on the search query.
    """
    prompt = f"""
    Given the following natural language search query, generate a JSON object containing filters for querying a DynamoDB table of receipts.

    Query: "{search_query}"

    The table contains the following attributes:
    - user_id (String)
    - vendor_name (String)
    - total_amount (Number)
    - transaction_date (String in YYYY-MM-DD format)
    - items (List of Maps with fields: item_name, quantity, price)

    Example output:
    {{
        "vendor_name": "Woolworths",
        "transaction_date": {{
            "start": "2023-09-01",
            "end": "2023-09-15"
        }}
    }}
    """

    # Call the LLM (e.g., OpenAI GPT or AWS Bedrock)
    response = openai.Completion.create(
        engine='text-davinci-003',
        prompt=prompt,
        max_tokens=150,
        temperature=0.2
    )

    # Extract and parse
